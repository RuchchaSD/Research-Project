%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Background & Related Work
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background \& Related Work}
\label{sec:related}

% This section surveys the landscape that motivates our cache-optimized, BLAS-centric
% approach.  We group prior art into five themes: the role of bundle adjustment (BA)
% in SLAM and structure-from-motion (SfM), numerical strategies based on
% Levenberg–Marquardt (LM) and the Schur complement, widely-used BA software
% libraries, dense BLAS–oriented acceleration, and finally embedded or
% multicore‐specific implementations.

%------------------------------------------------------------------------
\subsection{Bundle Adjustment in SLAM and SfM}
\label{sec:ba_slam}

% BA refines camera poses $\mathbf{T}_{wc}$ and 3-D points
% $\mathbf{X}\!\in\!\mathbb R^{3}$ by minimizing the reprojection cost
% $\sum_{i,j}\!\rho\!\bigl(\|\mathbf r_{ij}\|^{2}\bigr)$, where
% $\mathbf r_{ij}$ is the pixel error of landmark~$j$ in image~$i$ and
% $\rho(\cdot)$ is a robust loss~\cite{Hartley2003,Lourakis2009}.
% %
% \textbf{Global} pipelines such as COLMAP perform full BA after incremental
% reconstruction~\cite{Schonberger2016}, whereas real-time SLAM systems
% (e.g.\ ORB-SLAM3~\cite{MurArtal2021}) use \textbf{local} sliding-window BA to
% bound latency.  Window size, marginalization policy, and graph sparsity
% (edge fixing vs.\ landmark elimination) directly impact accuracy and runtime;
% comparative studies are given in~\cite{Engel2018,Usenko2019,Pfrommer2020}.

%------------------------------------------------------------------------
\subsection{Levenberg--Marquardt and the Schur Complement}
\label{sec:lm_schur}

% LM blends Gauss–Newton with a trust-region damping term
% $\lambda\operatorname{diag}(\mathbf J^{\!\top}\mathbf J)$, yielding robust
% convergence for ill-conditioned BA~\cite{Lourakis2005}.  Eliminating
% landmarks via the two-phase Schur complement reduces the normal equations to
% a camera-only system
% $\mathbf S\Delta\boldsymbol\theta=-\mathbf g$ whose assembly and solution
% dominate the computational cost~\cite{Agarwal2012,Chen2022}.  Recent work
% explores block-Jacobian tiling~\cite{Merry2016} and hierarchical damping
% schemes~\cite{Zhang2023}, yet memory traffic for forming $\mathbf S$
% remains the primary bottleneck.

%------------------------------------------------------------------------
\subsection{General-Purpose BA Libraries}
\label{sec:ba_libs}

% \textbf{g2o}~\cite{Kuemmerle2011}, \textbf{Ceres}~\cite{Agarwal2012} and
% \textbf{SBA}~\cite{Ni2007} expose flexible graph abstractions but rely on
% sparse block storage and CPU-centric factorization back-ends.  Their design
% decisions—dynamic memory, pointer-heavy containers, and irregular
% kernel launch patterns—complicate direct mapping to accelerators.  For
% instance, Ceres uses
% \texttt{BlockSparseMatrix} (compressed row) and an in-house
% \texttt{schur\_eliminator}, while g2o employs template metaprogramming for
% edge types; neither provides a BLAS-level interface.

%------------------------------------------------------------------------
\subsection{Dense BLAS APIs and Batched GEMM}
\label{sec:blas}

% Modern accelerators deliver peak throughput through hand-tuned BLAS 3
% routines.  GPU libraries such as \emph{cuBLAS} and FPGA toolchains like
% \emph{Vitis BLAS} offer batched GEMM kernels that amortize launch overhead
% across many small matrices.  MEGBA~\cite{Harhash2017} and MAGMA-BA
% demonstrate $2$–$3\times$ speed-ups by re-organizing BA blocks into dense
% tiles.  On ARM Cortex-A clusters, ARM Performance Libraries (ARMPL) attain
% $>$80\,\% of peak FLOP/W, outperforming sparse kernels both in energy and
% time~\cite{Zhang2024}.  However, all prior works require bespoke tiling
% logic tightly coupled to the target device.

%------------------------------------------------------------------------
\subsection{Embedded and Multicore BA Implementations}
\label{sec:embedded}

% FPGA accelerators such as $\pi$-BA~\cite{Liu2020} and BAX~\cite{Sun2020} achieve
% sub-millisecond Schur reductions but at steep LUT/BRAM cost or by shrinking
% problem size.  Jetson-class GPU solvers (e.g.\ the MEGBA Jetson port) face
% memory-bandwidth ceilings and kernel launch overhead~\cite{Harhash2017}.
% Many-core CPU efforts—Pollard \emph{et al.} on Xeon Phi~\cite{Pollard2015},
% Chen \emph{et al.} on Epyc Rome—are largely limited by cache capacity and DRAM
% traffic.  These observations motivate our three novelties:
% \emph{T\textsuperscript{2}SC}, \emph{BEC}, and \emph{CABR}, which together
% tile the Schur phase, route \emph{all} heavy kernels through standard BLAS,
% and eliminate pointer chasing via flat arrays.

%------------------------------------------------------------------------
% A taxonomy figure and a comparison table remain as placeholders.
\begin{figure}[t]
  \centering
  % TODO: replace with a real diagram of categories and example papers.
  \includegraphics[width=0.85\linewidth]{figs/placeholder}
  \caption{Taxonomy of BA acceleration strategies (placeholder).}
  \label{fig:rw_taxonomy}
\end{figure}

% \begin{table}[b]
%   \caption{Representative BA accelerators (placeholder).  “Dense” indicates
%            whether sparse blocks are re-packed into dense tiles; “Acc.”
%            lists the primary hardware accelerator used.}
%   \label{tab:rw_comparison}
%   \centering
%   \begin{tabular}{@{}lccc@{}}
%   \toprule
%   Method        & Dense?  & Parallel? & Embedded? \\ \midrule
%   Ceres-Sparse  & \xmark  & \xmark    & \xmark    \\
%   g2o           & \xmark  & \xmark    & \xmark    \\
%   Ours          & \cmark  & \cmark    & \cmark    \\ \bottomrule
% \end{tabular}
% \end{table}
