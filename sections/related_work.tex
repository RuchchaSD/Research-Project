%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Related Work
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background and Related Work}\label{sec:related_work}



This section revisits the classical bottlenecks of bundle adjustment (BA) and surveys three principal acceleration directions—CPU, 
GPU, and custom hardware—highlighting why a \emph{dense‑BLAS, cache‑aware CPU design} remains a compelling sweet‑spot for embedded 
robotics.

\subsection{Bundle Adjustment Bottlenecks and the Schur Complement}
\label{subsec:ba_bottlenecks} BA refines camera poses and 3‑D landmarks by minimizing re‑projection error via damped Gauss–Newton or Levenberg–Marquardt (LM) iterations \cite{triggs1999bundle,hartley2003multiple}. The normal equations 
induce a bipartite block Hessian:
\begin{equation}
\mathbf{H} = \begin{bmatrix}
\mathbf{A} & \mathbf{W} \\
\mathbf{W}^T & \mathbf{B}
\end{bmatrix}
\end{equation}
where $\mathbf{A}$, $\mathbf{B}$, and $\mathbf{W}$ encode pose–pose, landmark–landmark, and cross interactions. Early software such as
SBA~\cite{lourakis2009sba} constructed the full Hessian and used dense/banded factorisation, quickly becoming memory‑bound for thousands of landmarks.

The \textbf{Schur complement} eliminates landmarks analytically \cite{Konolige2010SparseSB}, forming the reduced camera system:
\begin{equation}
(\mathbf{A} - \mathbf{W}\mathbf{B}^{-1}\mathbf{W}^T)\boldsymbol{\delta}_{\text{poses}} = \mathbf{b}_{\text{poses}} - \mathbf{W}\mathbf{B}^{-1}\mathbf{b}_{\text{landmarks}}
\end{equation}
Although this reduces factorisation cost from $\mathcal{O}((n_p + n_l)^3)$ to $\mathcal{O}(n_p^3)$, constructing 
$\mathbf{H}_{\text{act}} = \mathbf{A} - \mathbf{W}\mathbf{B}^{-1}\mathbf{W}^T$ now dominates runtime (often $\geq$60\%) 
because it requires per‑landmark inversions and irregular block accumulations that thrash caches—especially on small L2/L3 
embedded CPUs.


\subsection{Acceleration Approaches}\label{subsec:acceleration}

\paragraph*{CPU‑based Solvers} Widely‑used libraries like \textsc{g2o}~\cite{kummerle2011g} and 
\textsc{Ceres}~\cite{agarwal2012ceres} implement the Schur complement using compressed sparse row (CSR) formats with 
scatter-gather operations that suffer from irregular memory access. While multithreaded Jacobian assembly and block-aligned
 storage~\cite{wu2011multicore} improve locality and demonstrate 2-3× speedups on embedded ARM processors, existing solvers 
 still spend over 50\% of runtime in memory-bound operations with frequent cache misses, especially when scaling beyond 
 one NUMA socket.

\paragraph*{GPU Approaches} Solutions like PBA~\cite{wu2011multicore} and MegBA~\cite{ren2022megba} parallelize Schur 
complement computation across thousands of GPU threads, achieving impressive 10-30× speedups over single-threaded CPU 
implementations. However, their high power requirements ($\geq$200W) and PCIe transfer overheads make them unsuitable for 
mobile robotics applications.

\paragraph*{Dedicated Hardware} FPGA/ASIC accelerators including $\pi$‑BA~\cite{qin2019pi} and BAX~\cite{sun2020bax} 
achieve millisecond-level Schur complement computation by streaming operations fully on-chip. While this enables 
significant energy savings, these designs face flexibility constraints - requiring substantial hardware resources 
(141.5 BRAMs for $\pi$‑BA, nearly exhausting the 144 BRAMs available on modern K26 SoCs) or imposing strict problem size limits (16 poses, 256 landmarks for BAX).

\begin{figure}[t]
  \centering
  % TODO: replace with a real diagram of categories and example papers.
  \includegraphics[width=0.85\linewidth]{figs/placeholder}
  \caption{Taxonomy of BA acceleration approaches: (1) CPU solvers like g2o/Ceres using CSR formats and scatter-gather operations, 
  (2) GPU solutions like PBA/MegBA leveraging thousands of threads but requiring high power, (3) FPGA/ASIC accelerators like 
  $\pi$-BA/BAX achieving millisecond latency with resource constraints, and (4) our dense BLAS approach enabling portable 
  acceleration via vendor-optimized libraries.}
  \label{fig:rw_taxonomy}
\end{figure}

\subsection{BLAS APIs for Hardware Acceleration}\label{subsec:blas_apis}

Modern processors and accelerators expose optimized matrix operations through standardized BLAS APIs~\cite{blackford2002updated}, 
enabling portable access to vendor-tuned kernels like batched \texttt{GEMM} and \texttt{SYRK}. Key implementations include 
Intel oneMKL, Arm Performance Libraries (ArmPL), OpenBLAS, NVIDIA cuBLAS, and Xilinx Vitis BLAS~\cite{intel2023mkl,arm2023armpl,openblas2023,nvidia2025cublas,xilinx2024vitisblas}.

These libraries deliver 80–95\% of peak FLOPS for BA-relevant matrix sizes (32–96 blocks) by leveraging specialized 
instructions: oneMKL uses AMX tiles on Xeon, ArmPL employs SVE2 on Cortex-A, and cuBLAS dispatches Tensor Cores via 
\texttt{cublasGemmEx}. However, existing BA solvers fail to exploit this potential due to irregular sparse operations that 
bypass Level-3 BLAS entirely. Our approach systematically maps the complete Schur complement pipeline to dense BLAS calls, 
achieving portable acceleration across all these platforms.

Despite these advances, existing BA solvers remain memory-bound due to pointer-based sparse structures and irregular access 
patterns that bypass Level-3 BLAS optimizations entirely. Our approach addresses this fundamental limitation through 
comprehensive redesign of the Schur complement pipeline using dense parameter ordering 
(\S\ref{subsec:parameter_ordering}), flat connectivity arrays (\S\ref{subsec:connectivity_storage}), T²SC tiling 
(\S\ref{subsec:t2sc}), and complete BLAS mapping (\S\ref{subsec:blas_apis}) to achieve cache-friendly, portable acceleration 
across CPU architectures.

%------------------------------------------------------------------------
% A taxonomy figure and a comparison table remain as placeholders.


% \begin{table}[b]
%   \caption{Representative BA accelerators (placeholder).  "Dense" indicates
%            whether sparse blocks are re-packed into dense tiles; "Acc."
%            lists the primary hardware accelerator used.}
%   \label{tab:rw_comparison}
%   \centering
%   \begin{tabular}{@{}lccc@{}}
%   \toprule
%   Method        & Dense?  & Parallel? & Embedded? \\ \midrule
%   Ceres-Sparse  & \xmark  & \xmark    & \xmark    \\
%   g2o           & \xmark  & \xmark    & \xmark    \\
%   Ours          & \cmark  & \cmark    & \cmark    \\ \bottomrule
% \end{tabular}
% \end{table}
