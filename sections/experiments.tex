\section{Experimental Setup}
\label{sec:experiments}

This section details the hardware, datasets, baselines, and evaluation metrics used to benchmark our cache-optimized bundle‑adjustment (BA) solver.

\subsection{Benchmark Platforms}
\label{subsec:exp_platforms}
We evaluate on two heterogeneous CPUs to expose the impact of cache capacity versus memory bandwidth:
\begin{itemize}
\item \textbf{Quad‑core Cortex‑A53} (Kria KR260 starter kit) (@\SI{1.5}{GHz}), \SI{512}{kB} 
shared L2 and \SI{4}{GB} LPDDR4. The solver is compiled with \texttt{gcc 13} using 
\texttt{-O3 -march=cortex-a53} and links against \emph{Arm Performance Libraries 23.04} BLAS.
\item \textbf{16‑core Intel(R) Core(TM) i9‑9900K CPU} (@\SI{3.60}{GHz}), \SI{16}{MB} LLC and
\SI{32}{GB} DDR4‑3200. We compile with \texttt{gcc 13} and link Eigen's BLAS shim to 
\emph{OpenBLAS 0.3.8}; flags: \texttt{-O3 -march=native -fopenmp}.
\end{itemize}

\subsection{Datasets and Problem Sizes}
\label{subsec:exp_datasets}
We evaluate on the Bundle Adjustment in the Large (BAL) dataset \cite{agarwal2010bundle}, which provides a
diverse set of real-world reconstruction problems. Since our target application is real-time SLAM with bounded
window sizes, we focus on five medium-scale scenes: \textit{Ladybug-1}, \textit{Dubrovnik-1}, 
\textit{Ladybug-2}, \textit{Trafalgar-3}, and \textit{Ladybug-3}. These scenes span a representative range of 
problem sizes while remaining within typical SLAM memory budgets. Table~\ref{tab:exp_datasets} summarizes the 
key statistics for each scene: basic problem structure (cameras, landmarks, observations, co-observations) and 
derived complexity metrics including density ratios and the number of $\mathbf Y_i\mathbf W_i^{\top}$ operations 
required for Schur complement construction (derived from landmark co-visibility patterns).
Each camera in the BAL dataset has 9 parameters: 3 for rotation, 3 for translation, 
1 for focal length, and 2 for radial distortion coefficients. 
These camera intrinsics (focal length) and distortion parameters are 
jointly optimized along with the camera poses during bundle adjustment.

\begin{table}[b]
\caption{BAL dataset statistics showing problem structure and complexity.}
\label{tab:exp_datasets}
\centering
\footnotesize
\begin{tabular}{@{}lcccc@{}}
\toprule
\multicolumn{5}{c}{\textbf{Problem Structure}} \\
\midrule
Dataset & Cameras & Landmarks & Observations & Co-Obs \\
\midrule
Ladybug‑1   & 49  & 7776  & 31843 & 91243 \\
Dubrovnik‑1 & 16  & 22106 & 83718 & 170046 \\
Ladybug‑2   & 73  & 11032 & 46122 & 147691 \\
Trafalgar‑3 & 50  & 20431 & 73967 & 172026 \\
Ladybug‑3   & 138 & 19878 & 85217 & 328220 \\
\midrule
\multicolumn{5}{c}{\textbf{Complexity Metrics}} \\
\midrule
Dataset & O/C & O/L & L/C & \# of $\mathbf Y_i\mathbf W_i^{\top}$ \\
\midrule
Ladybug‑1   & 649.9 & 4.10 & 158.7  & 123086 \\
Dubrovnik‑1 & 5232.4 & 3.79 & 1381.6 & 253764 \\
Ladybug‑2   & 631.8 & 4.18 & 151.1 & 193813 \\
Trafalgar‑3 & 1479.3 & 3.62 & 408.6 & 245993 \\
Ladybug‑3   & 617.5 & 4.29 & 144.0 & 413437 \\
\bottomrule
\end{tabular}
\end{table}

% -------------------------------------------------------
\subsection{Synthetic Scalability Suite}
\label{subsec:exp_synth}
To validate that our runtime grows \emph{only} with the true
computational workload (the number of $\mathbf Y_i\mathbf W_i^{\top}$
tiles) we created a controlled, synthetic bundle-adjustment family.
Each landmark is observed exactly four times, yielding a fixed sparse
pattern that isolates Schur-complement work from visibility changes.
\begin{itemize}
  \item \textbf{Pose sweep:} Landmarks fixed at \textbf{10k}; poses varied
        from 10 to 100 in steps of 10 (detailed in Appendix~\ref{app:additional_results}).
  \item \textbf{Landmark sweep:} Poses fixed at \textbf{40}; landmarks
        varied from 10k to 100k in steps of 10k
        (detailed in Appendix~\ref{app:additional_results}).
\end{itemize}


\subsection{Baselines and Solver Configuration}
\label{subsec:exp_baselines}
We compare against the widely used open‑source BA library:
\begin{itemize}
\item \textbf{g2o 2.3.5} in Levenberg–Marquardt mode using the block‑sparse 
CSR backend with OpenMP, Cholmod, and CSparse support enabled. The solver is 
built with SuiteSparse dependencies (AMD, CAMD, CCOLAMD, CHOLMOD, COLAMD, SPQR) 
and Intel TBB 2022.0.
% \item \textbf{Ceres Solver 2.3.0-eigen-(3.3.7)-lapack-eigensparse} with Schur‑Jacobi preconditioner and \texttt{OpenMP} threading. Ceres uses the same LM algorithm with parameter scaling as our method.
\end{itemize}
As done in ORB-SLAM3 \cite{campos2021orb}, all solvers are limited to \textbf{ten outer LM iterations} to match 
the typical real‑time budget of sliding‑window local Bundle Adjustment in visual SLAM systems.

\subsection{Evaluation Metrics}
\label{subsec:exp_metrics}
Reported quantities are:
\begin{enumerate}
\item Wall‑clock time for the first ten LM iterations.
\item Mean time per outer iteration (runtime / 10).
\item $\chi^{2}$ reprojection cost after iteration 10, and after full convergence of Ceres solver to evaluate each method's relative performance.
\item Peak memory usage (RAM) measured through the resident set size (RSS) metric using \texttt{/proc/\$PID/statm} system file.
\end{enumerate}
Each experiment is repeated three times; we report the mean with standard deviation below \SI{2}{\percent}.